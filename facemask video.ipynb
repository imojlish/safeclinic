{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary packages (if running in Colab)\n",
    "!pip install opencv-python\n",
    "from google.colab.patches import cv2_imshow  # Only needed if you're using Colab\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def face_mask_detector(frame):\n",
    "    # Create a blurred version of the background\n",
    "    blurred_frame = cv2.GaussianBlur(frame, (21, 21), 0)\n",
    "\n",
    "    # Convert the frame to grayscale for face detection\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = faceCascade.detectMultiScale(gray,\n",
    "                                         scaleFactor=1.1,\n",
    "                                         minNeighbors=5,\n",
    "                                         minSize=(60, 60),\n",
    "                                         flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "\n",
    "    # Create a mask with the same shape and type as the frame\n",
    "    mask = np.zeros_like(frame, dtype=np.uint8)\n",
    "\n",
    "    # Process each detected face\n",
    "    for (x, y, w, h) in faces:\n",
    "        # Extract face region\n",
    "        face_frame = frame[y:y+h, x:x+w]\n",
    "\n",
    "        # Preprocess face for mask model\n",
    "        face_frame_rgb = cv2.cvtColor(face_frame, cv2.COLOR_BGR2RGB)\n",
    "        face_frame_resized = cv2.resize(face_frame_rgb, (224, 224))\n",
    "        face_frame_array = img_to_array(face_frame_resized)\n",
    "        face_frame_array = np.expand_dims(face_frame_array, axis=0)\n",
    "        face_frame_array = preprocess_input(face_frame_array)\n",
    "\n",
    "        # Predict mask or no mask\n",
    "        faces_list = [face_frame_array]\n",
    "        preds = model.predict(faces_list)\n",
    "\n",
    "        # Process prediction results\n",
    "        for pred in preds:\n",
    "            (mask_prob, withoutMask) = pred\n",
    "            label = \"Mask\" if mask_prob > withoutMask else \"No Mask\"\n",
    "            color = (0, 255, 0) if label == \"Mask\" else (0, 0, 255)\n",
    "            label = \"{}: {:.2f}%\".format(label, max(mask_prob, withoutMask) * 100)\n",
    "\n",
    "            # Draw label and bounding box on original frame\n",
    "            cv2.putText(frame, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)\n",
    "\n",
    "            # Keep the face region in focus by copying it onto the mask\n",
    "            mask[y:y+h, x:x+w] = face_frame  # Assign the face area to the mask\n",
    "\n",
    "    # Combine blurred background and the mask to keep the face in focus\n",
    "    output_frame = np.where(mask > 0, mask, blurred_frame)\n",
    "\n",
    "    return output_frame\n",
    "\n",
    "# Video processing function\n",
    "def process_video(video_path):\n",
    "    # Open the video file\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # Check if the video file opened successfully\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video.\")\n",
    "        return\n",
    "\n",
    "    # Process each frame in the video\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break  # Exit if no more frames are available\n",
    "\n",
    "        # Detect face masks in the current frame\n",
    "        output_frame = face_mask_detector(frame)\n",
    "\n",
    "        # Display the frame (in Colab use cv2_imshow)\n",
    "        cv2_imshow(output_frame)  # For Colab\n",
    "        # cv2.imshow(\"Face Mask Detection\", output_frame)  # Uncomment for local execution\n",
    "\n",
    "        # Exit if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release the video capture object and close display window\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Call the function with your video path\n",
    "process_video(\"video.mp4\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
